# diplom
файл дипломного проекта
В дипломном проекте поставлена задача разработать сервис для предсказания стоимости домов на основе истории предложений
В данные включены следующие признаки
'status' - статус продажи
'private pool’ и 'PrivatePool' - наличие частного бассейна,
'propertyType' - тип недвижимости, поместья, свойства,
'street' - адрес дома
'baths' - количество ванных комнат
'homeFacts' - сведения о строении дома, содержит несколько отдельных данных, имеющих влияние на оценку недвижимости, дома, квартиры
'fireplace' - сведения о наличии камина (ов) в доме
'city' - город
'schools' - сведения о школах в районе
'sqft' - площадь дома в футах
'zipcode' - почтовый индекс
'beds' - количество спален в доме
'state' - государство/штаты
'stories' - этажность недвижимости
'mls-id' и 'MlsId' - идентификатор MLS (Multiple Listing Service - Служба множественного листинга)
'target' - целевой признак, который необходимо спрогнозировать - цена недвижимости
Для решения задачи:
-установили необходимые библиотеки
-подгрузили данные,
-провели очистку данных и подготовим их к построению модели,
-удалили дубликаты и признаки с нулевыми значениями более 30%,
-сформировали новые признаки и переводим их в числовые,
-с помощью графика коробчатой гистограммы статистической обработки оценили и удалили выбросы в данных,
-оценили возможность построения простой модели линейной корреляции,
-сильной корреляции признаков с целевым не обнаружено,
-построили простые модели регрессии и оценили метрики,

Простые модели показывают хорошую МАРЕ и слабую R2/
Визуализация ошибок модели показала присутствие наблюдений, сильно выбивающихся за пределы усов. Это наблюдения, для которых модель допустила очень большую ошибку, по сравнению с основной группой.
Можно предположить, что линейной модели не хватает для предсказания целевой переменной для таких объектов.
Далее строим модели случайного леса и стекинга и делаем пайплайн.
Усложнение моделей приводит к увеличению времени выполнения кода, но улучшает качество метрик по сравнению с простыми моделями.


